{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question1 \n",
    "Based on this data, what can we conclude at this point from the A/B test (in which we tried initiating the background check earlier in the hiring process for the treatment shoppers)? And how confident should we be in this conclusion?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('application.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "df['applicant_id'] = df['applicant_id'].astype('object')\n",
    "df['event_date'] = df['event_date'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('group').agg({'applicant_id': 'nunique'})  # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('group').agg({'applicant_id': 'count'})  # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check converstion funnel and its sequence by group\n",
    "print (df[df['group'] == 'control'].groupby(['group','event']).applicant_id.nunique().sort_values(ascending = False))\n",
    "print (df[df['group'] == 'treatment'].groupby(['group','event']).applicant_id.nunique().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nominator\n",
    "cvr = pd.DataFrame(df.groupby(['group','event']).applicant_id.nunique().sort_values(ascending = False))\n",
    "cvr = cvr.sort_values(['group','applicant_id'], ascending = False).reset_index()\n",
    "\n",
    "##demoninator\n",
    "demoninator = pd.DataFrame(cvr.groupby('group').applicant_id.max()).reset_index()\n",
    "\n",
    "## rate\n",
    "cvr1 = cvr.merge(demoninator, left_on = 'group', right_on = 'group').reset_index(drop = True)\n",
    "cvr1['rate'] = cvr1['applicant_id_x']/cvr1['applicant_id_y']\n",
    "cvr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check experiment duration\n",
    "print(df['event_date'].min())\n",
    "print(df['event_date'].max())\n",
    "\n",
    "df['event_date'].max() - df['event_date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the dataset by applicant\n",
    "df_transpose = df.pivot_table(index = ['group','applicant_id'],columns = 'event',values = 'event_date', aggfunc='max')\n",
    "df_transpose.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the distribution of the duration of the days between application_date to first_batch_completed_date\n",
    "import seaborn as sns\n",
    "duration = (df_transpose['first_batch_completed_date'] - df_transpose['application_date'])\n",
    "sns.distplot(duration[duration.notna()].dt.days, hist_kws={'cumulative':'True'}, kde_kws= {'cumulative':'True'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind the conversion windows\n",
    "# application date range from [2018-10-01 00:00:00, 2018-10-31 00:00:00]  80% -> duration 11 days\n",
    "\n",
    "qualified_applicant_id = pd.DataFrame(df.loc[(df['event'] == 'application_date') \n",
    "                                             & (df['event_date'] <= '2018-10-31'),'applicant_id'].unique())\n",
    "qualified_applicant_id.columns = ['qualified_applicant_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out who are not qualified in this experiment\n",
    "\n",
    "df = df.merge(qualified_applicant_id,left_on = 'applicant_id', right_on = 'qualified_applicant_id', \n",
    "              how = 'inner').reset_index(drop = True)\n",
    "df = df[['applicant_id','channel','group','city','event','event_date']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check convertsion funnel\n",
    "\n",
    "print (df[df['group'] == 'control'].groupby(['group','event']).applicant_id.nunique().sort_values(ascending = False))\n",
    "print (df[df['group'] == 'treatment'].groupby(['group','event']).applicant_id.nunique().sort_values(ascending = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the invariate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - sample size\n",
    "# define invariate check function\n",
    "\n",
    "def invariant_check(test_sample_size, control_sample_size, p_pool, z_score):\n",
    "    import numpy as np\n",
    "    p_pool_sd = np.sqrt(p_pool * (1 - p_pool)/(test_sample_size + control_sample_size))\n",
    "    margin_error = p_pool_sd * z_score\n",
    "    control_prop = control_sample_size/(test_sample_size + control_sample_size)\n",
    "    confidence_interval_lower = p_pool - margin_error\n",
    "    confidence_interval_upper = p_pool + margin_error   \n",
    "    return confidence_interval_lower, confidence_interval_upper, control_prop\n",
    "\n",
    "test_sample = df.groupby('group').agg({'applicant_id': 'nunique'}).loc['treatment','applicant_id']\n",
    "control_sample = df.groupby('group').agg({'applicant_id': 'nunique'}).loc['control','applicant_id']\n",
    "lower, upper, control_prop = invariant_check(test_sample,control_sample,0.5,1.96)\n",
    "\n",
    "print ('confidence interval lower bounds: {}'.format(lower))\n",
    "print ('confidence interval upper bounds: {}'.format(upper))\n",
    "print ('control proportion: {}'.format(control_prop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# choose metrics\n",
    "# conversion rate = complete first batch / application \n",
    "# calculate z score\n",
    "\n",
    "# define z_score function\n",
    "def z_score_pool(test_success, control_success, test_sample_size, control_sample_size):\n",
    "    import numpy as np\n",
    "    d = test_success/test_sample_size - control_success/control_sample_size\n",
    "    p_pool = (test_success + control_success)/(test_sample_size + control_sample_size)\n",
    "    p_pool_sd = np.sqrt(p_pool*(1-p_pool)*(1/test_sample_size + 1/control_sample_size))\n",
    "    z_score = (d-0) / p_pool_sd\n",
    "    return z_score\n",
    "\n",
    "test_complete = 2115\n",
    "contrl_complete = 2678\n",
    "test_sample_size = 4958\n",
    "control_sample_size = 10024\n",
    "alpha = 0.05\n",
    "dmin = 0  # no prtical significant value provided, then we can assume dmin = 0\n",
    "\n",
    "z = z_score_pool(test_complete, contrl_complete, test_sample_size, control_sample_size)\n",
    "p_value = (1-stats.norm.cdf(z))\n",
    "print ( 'z score is %s > 1.65, so we can reject null hypothesis, and accept alternative hypothesis' %z )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "- The background check costs us $30 to complete!  \n",
    "- We'd like to know if this change is cost-effective. How should we think about the cost-effectiveness of this change? Please be as specific as you can here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 30\n",
    "\n",
    "# formula: cost per success\n",
    "\n",
    "control = (30*8582)/ 2678\n",
    "test =  (30*4958)/ 2115\n",
    "print (control)\n",
    "print (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_cvr = df_transpose.groupby('channel').agg({'application_date':'count','first_batch_completed_date':'count' })\n",
    "channel_cvr['cvr'] = channel_cvr['first_batch_completed_date']/channel_cvr['application_date']\n",
    "channel_cvr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_cvr_group = df_transpose.groupby(['group','channel']).agg({'application_date':'count','first_batch_completed_date':'count'})\n",
    "channel_cvr_group['cvr'] = channel_cvr_group['first_batch_completed_date']/channel_cvr_group['application_date']\n",
    "channel_cvr_group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (default, Dec 21 2020, 15:06:04) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
